{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7712a5ae-5309-43c0-b641-160828bd8f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyTorch 基本运算示例\n",
    "Torch的tensor和Numpy的Array，Pandas的Series和Dataframe类似，是了解应用这些代码库的基础，这里首先简单快速地了解Tensor及如何使用GPU，然后日常积累一些常用张量运算函数。\n",
    "\n",
    "主要参考：\n",
    "\n",
    "- TENSORS\n",
    "- Speed Up your Algorithms Part 1 — PyTorch\n",
    "- PyTorch 101, Part 1: Understanding Graphs, Automatic Differentiation and Autograd\n",
    "# 快速了解Tensor\n",
    "pytorch作为NumPy的替代品，可以利用GPU的性能进行计算；可作为一个高灵活性、速度快的深度学习平台。\n",
    "\n",
    "Tensor（张量）类似于NumPy的ndarray，但还可以在GPU上使用来加速计算。因此经常看到把numpy的数组包装为tensor再运算。tensor的操作和numpy中的数组操作类似，不再赘述，详见官网。下面列举一些简单例子。首先pytorch的导入是import torch，因为torch一直都是那个torch，一开始是别的语言写的，现在在python下，所以就叫pytorch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9916ed3-d0f4-4dd9-84de-be1fddfc1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59994acb-88aa-4bfd-beee-3b17dd345192",
   "metadata": {},
   "source": [
    "Tensor是pytorch的基本数据类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0b175e-9890-4bba-acc5-6f175f972085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5)\n",
    "# 如果想要从tensor中获取到长度的int数据\n",
    "type(list(x.shape)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3d5150-3523-4a70-9d2a-1ebfc2211211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.1996e-10, 2.6430e-06, 6.7384e-10],\n",
       "        [2.6877e-06, 2.1707e-18, 1.6678e+19],\n",
       "        [7.0976e+22, 2.1715e-18, 4.2330e+21],\n",
       "        [1.6534e+19, 1.1625e+27, 1.4580e-19],\n",
       "        [7.1856e+22, 4.3605e+27, 1.5766e-19]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建一个 5x3 的矩阵, 未初始化的:\n",
    "x = torch.Tensor(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757759c-883b-44f1-9aca-d40117c15e7f",
   "metadata": {},
   "source": [
    "pytorch中的一些基本运算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5164a55-2b6e-47af-bd44-188c6c059619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2817, 0.9947, 0.6288],\n",
       "        [0.0626, 0.0664, 0.3572],\n",
       "        [0.3648, 0.5679, 0.7972],\n",
       "        [0.7478, 0.9677, 0.2950],\n",
       "        [0.1525, 0.6056, 0.1925]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建一个随机初始化的矩阵:\n",
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe8398b-8d5f-44e0-8aac-4036b0b10445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0455e5-81c3-4f07-9d26-8d057f48a5ae",
   "metadata": {},
   "source": [
    "concatenate的操作使用torch.cat可以完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a098882-cfd8-40f5-aa31-04a276a20951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2202e-37,  1.0457e-12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.Tensor(1)\n",
    "x2 = torch.Tensor(1)\n",
    "torch.cat((x1,x2),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb94d8c-0cf3-4793-95d1-c995e0d3c52b",
   "metadata": {},
   "source": [
    "可以看到torch中的size也是torch中的类，包装了python的list，自然地，加减运算的对象也都是torch的tensor了。运算可以使用运算符，也可以使用函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b07a7e-1281-417a-9a28-b6e5e64ba854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8849, 1.6596, 1.6231],\n",
       "        [0.7306, 0.4764, 0.4485],\n",
       "        [0.9049, 1.5603, 0.9853],\n",
       "        [1.1247, 1.0984, 0.5352],\n",
       "        [0.9925, 1.2544, 0.3658]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法\n",
    "y = torch.rand(5, 3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc34ac4c-abb5-408c-ba3a-37fceae367bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8849, 1.6596, 1.6231],\n",
       "        [0.7306, 0.4764, 0.4485],\n",
       "        [0.9049, 1.5603, 0.9853],\n",
       "        [1.1247, 1.0984, 0.5352],\n",
       "        [0.9925, 1.2544, 0.3658]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dc9bf6d-205c-4363-9de3-78d061eac8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8849, 1.6596, 1.6231],\n",
       "        [0.7306, 0.4764, 0.4485],\n",
       "        [0.9049, 1.5603, 0.9853],\n",
       "        [1.1247, 1.0984, 0.5352],\n",
       "        [0.9925, 1.2544, 0.3658]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out = result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29cc12c5-c9bc-434d-a319-3e84ae4206e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a.add_(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59b1ab-0609-498d-9058-ad3ab9c9e6ad",
   "metadata": {},
   "source": [
    "numpy和tensor之间有很多类似的地方，比如索引，形状改变等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb50430e-7b1b-48ff-a8fa-dceb37a07993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9947, 0.0664, 0.5679, 0.9677, 0.6056])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以用类似Numpy的索引来处理所有的张量！\n",
    "x[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a47210c-3da1-42ba-8839-6f9333735138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([[-0.4537,  0.5050,  1.6169,  0.4171],\n",
      "        [-2.9974, -1.1606,  0.5544, -2.9557],\n",
      "        [ 0.0497,  1.6970,  1.4802,  0.1655],\n",
      "        [-1.0053, -1.4187,  0.1339,  0.1888]])\n",
      "tensor([-0.4537,  0.5050,  1.6169,  0.4171, -2.9974, -1.1606,  0.5544, -2.9557,\n",
      "         0.0497,  1.6970,  1.4802,  0.1655, -1.0053, -1.4187,  0.1339,  0.1888])\n",
      "tensor([[-0.4537,  0.5050,  1.6169,  0.4171, -2.9974, -1.1606,  0.5544, -2.9557],\n",
      "        [ 0.0497,  1.6970,  1.4802,  0.1655, -1.0053, -1.4187,  0.1339,  0.1888]])\n"
     ]
    }
   ],
   "source": [
    "# 改变大小: 如果你想要去改变tensor的大小, 可以使用 torch.view:\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # -1就是让pytorch自己根据其他的维度去判断这里该是几维\n",
    "print(x.size(), y.size(), z.size())\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f3504-b0e0-4b49-ab61-aeec92e38668",
   "metadata": {},
   "source": [
    "由于和numpy的紧密联系，因此pytorch的张量和numpy数组可以很方便的转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabcea04-897b-4b97-a505-f43b958f3f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945fbe58-6d0a-4382-9fbc-19acadbf1808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3547e57-931f-45e8-912d-a2ed389d6362",
   "metadata": {},
   "source": [
    "要注意numpy的array和torch的tensor转换后，数据是绑定的，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4ef3498-9bdd-4cc9-9d87-79a975f5b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy的array： [1. 1. 1. 1. 1.]\n",
      "array转为torch的tensor： tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 看改变 np 数组之后 Torch Tensor 是如何自动改变的\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(\"numpy的array：\",a)\n",
    "print(\"array转为torch的tensor：\",b)\n",
    "np.add(a, 1, out = a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81a1ad51-966a-4c4e-ba57-c54c28256790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 4., 4., 4., 4.], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 可以使用 .cuda 方法将 Tensors 在GPU上运行.\n",
    "# 只要在  CUDA 是可用的情况下, 我们可以运行这段代码\n",
    "if torch.cuda.is_available():\n",
    "    b = b.cuda()\n",
    "    print(b + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a1fc3-7407-4c15-b45c-2375cd0c647b",
   "metadata": {},
   "source": [
    "CPU上的所有张量(CharTensor除外)都支持与Numpy的相互转换。\n",
    "\n",
    "张量要在GPU上计算，需要主动从CPU移动到GPU上。张量可以使用.to方法移动到任何设备（device）上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "501538a3-2acd-4ae7-b877-e98e2757ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8086])\n",
      "0.8085774183273315\n",
      "tensor([1.8086], device='cuda:0')\n",
      "tensor([1.8086], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "# 当GPU可用时,我们可以运行以下代码\n",
    "# 我们将使用`torch.device`来将tensor移入和移出GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上创建tensor\n",
    "    x = x.to(device)                       # 或者使用`.to(\"cuda\")`方法\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # `.to`也能在移动时改变dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5187e4-b4fe-4341-a17d-704ffe533866",
   "metadata": {},
   "source": [
    "## GPU or CPU\n",
    "检查 cuda 设备是否可用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa50d16-ff14-4347-a1ad-91c7996bc366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "925cf1c0-cd90-4d25-a594-e964bb04f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果有GPU的话 可以执行下面几个注释掉的代码\n",
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba7e67cb-1b05-47da-87d4-66eb4bcfbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f81ee26b-90d4-436f-bc58-08aa712dd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the current GPU memory usage by tensors in bytes for a given device\n",
    "# torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "057c11bb-8640-4f24-b3da-89677117a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the current GPU memory managed by the caching allocator in bytes for a given device\n",
    "# torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e96c82-2243-4478-8b4f-47c4f6521249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Releases all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible in nvidia-smi\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca6eff-1bf8-4475-b981-97c33a710be5",
   "metadata": {},
   "source": [
    "如何使用GPU？\n",
    "\n",
    "如果像存储数据到CPU，那么简单定义即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "068bf21d-94c9-4cc6-84c2-7f9e4019d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.DoubleTensor([1., 2.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cb099-326c-4aaa-b526-c2abbca647eb",
   "metadata": {},
   "source": [
    "这时候变量在CPU上，且后续的运算都会在CPU上，为了将数据转移到GPU上，需要使用 .cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b346ab-22ef-4a32-a33b-848b3b41b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.FloatTensor([1., 2.]).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ce4d7-f53c-46a1-be4e-a16f05fe461a",
   "metadata": {},
   "source": [
    "或者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36c3f957-bd79-42a4-844e-21f5661a4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.cuda.FloatTensor([1., 2.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620c9bf-28a6-4591-ab3d-ee81ca602c95",
   "metadata": {},
   "source": [
    "这时候数据就在GPU上。模型同样可以转移到GPU上，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "834e76ed-2e81-4d2b-831e-106b3ea1a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "model = nn.Sequential(\n",
    "         nn.Linear(20, 20),\n",
    "         nn.ReLU(),\n",
    "         nn.Linear(20, 4),\n",
    "         nn.Softmax()\n",
    ")\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b6456-acf6-4094-98ba-2a1ebd7720f9",
   "metadata": {},
   "source": [
    "检查在不在GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4a79def-40a9-42fd-afe3-58ec25c1574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062fd27-bd20-4465-9652-f906d2bc0907",
   "metadata": {},
   "source": [
    "如果有多个GPU，可以使用Data Parallelism，拆分数据，将 Data Generator 拆分到更小的mini batches，然后送到多个GPUs\n",
    "\n",
    "PyTorch中，并行通过torch.nn.DataParallel实现。一些关键函数：：\n",
    "\n",
    "- Replicate：Module在多个设备上复制。\n",
    "- Scatter：input在这些设备的第一维中分布。\n",
    "- Gather：从这些设备收集input和连接第一维。\n",
    "- parallel_apply：将从Scatter获得的一组输入分布式应用于从Replicate获得的相应的分布式Modules。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e2eada9-ab48-42cc-ad59-2a4732c1a355",
   "metadata": {},
   "source": [
    "# Replicate module to devices in device_ids\n",
    "replicas = nn.parallel.replicate(module, device_ids)\n",
    "# Distribute input to devices in device_ids\n",
    "inputs = nn.parallel.scatter(input, device_ids)\n",
    "# Apply the models to corresponding inputs\n",
    "outputs = nn.parallel.parallel_apply(replicas, inputs)\n",
    "# Gather result from all devices to output_device\n",
    "result = nn.parallel.gather(outputs, output_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86365440-8047-491d-ad5a-6e860d8c8536",
   "metadata": {},
   "source": [
    "或者一种更简单的方式：\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=device_ids)\n",
    "result = model(input)\n",
    "\n",
    "更多信息可以关注：\n",
    "\n",
    "- Multi-GPU Framework Comparisons\n",
    "- ilkarman/DeepLearningFrameworks\n",
    "下面是Tensor的常见计算，日常积累。\n",
    "\n",
    "# 基本算术运算\n",
    "Tensor是一种数据结构，是 PyTorch 的基本构建块。Tensors 非常像 numpy 数组，与 numpy 不同的是，张量旨在利用 GPU 的并行计算能力。许多 Tensor 语法类似于 numpy 数组的语法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60064b42-24f9-49b6-9d68-cb213dbfc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbd387-5f63-4d5d-93c6-66170648f9f6",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "直接调用Tensor即可完成初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "534a9d31-5aa8-4071-a497-458e332fd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.Tensor(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3bda5-9f06-42ab-a925-4c5a415df3bc",
   "metadata": {},
   "source": [
    "和numpy不同的是，为了完成梯度下降等优化计算，Tensor还有梯度相关的属性（后续文本会有更多介绍），初始化时候requires_grad默认是False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "010580c7-94fc-4d40-9268-06c5aa93e594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58348d71-a921-47cf-8367-48896870a327",
   "metadata": {},
   "source": [
    "初始化为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bf9640b-7ac3-49e3-b317-033cd64e7d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206a173-91f1-4ea7-a2b6-ee0fc65f089a",
   "metadata": {},
   "source": [
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd95b6-4adf-46bb-ac6c-0b28ee7ce4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_one = torch.ones(4)\n",
    "t_one.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35b75c-17e1-4a5d-882b-8952e091de8e",
   "metadata": {},
   "source": [
    "requires_grad具有传染性。这意味着当通过对其他Tensors运算创建一个Tensor，且其中至少有一个用于创建的张量requires_grad被设置为True时，运算结果Tensor的requires_grad也将被设置为True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28750867-c561-4ad7-a75b-1d538403b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3,3), requires_grad = True)\n",
    "w1 = torch.randn((3,3))\n",
    "b = w1*a \n",
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a0051-59b8-476f-919d-276c619e4e9c",
   "metadata": {},
   "source": [
    "如果想要计算后的张量不被前序变量传染，可以使用detach()（非inplace运算），先detach()再计算即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0acfd2-d240-4afc-b07f-3fa3a31f8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_detach = w1*(a.detach())\n",
    "b_detach == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a581b-dfb5-4324-aad5-c6cd824b111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_detach.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e6d1b-8953-408c-b3a6-2820d231690e",
   "metadata": {},
   "source": [
    "detach()不是inplace运算，所以a还是有requires_grad的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dd4a5-6e0e-4718-b90f-3642f53477c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67347eaf-d4f2-4ff3-837a-a42ac9ab5f6c",
   "metadata": {},
   "source": [
    "## 均值计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f689114-3368-4c78-9e67-3000f6632e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(6,4)\n",
    "print(X,X.shape)\n",
    "avg_np, _ = np.average(X, axis=0, returned=True)\n",
    "avg_np, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775431f5-b70a-4c24-b230-d6ec9fe43d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_th = torch.tensor(X)\n",
    "avg_th = torch.mean(X_th, dim=0)\n",
    "avg_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730510d-d8e3-4888-854b-bffaa1d535bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (X == X_th.numpy()).all()\n",
    "# assert (avg_np == avg_th.numpy()).all()   # this fails alread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42734d74-4487-4beb-96c5-e542fd188d16",
   "metadata": {},
   "source": [
    "## 求和计算\n",
    "求和运算和平均运算类似：\n",
    "\n",
    "ta=torch.ones(5)\n",
    "tc=torch.sum(ta)\n",
    "tc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef3b60-13ce-4b82-8dc4-f843340912b9",
   "metadata": {},
   "source": [
    "## 幂次计算\n",
    "PyTorch下张量进行幂次计算需要使用 torch.pow 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77797a0-6e04-4c26-b1a2-1dce79451035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca6b40-203a-46ee-8852-ec3535939f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.pow(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440c6cc-51a0-465a-a5c6-069605128b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.pow(a, torch.Tensor([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a46c8-dca9-4911-9a66-39baa74f62d0",
   "metadata": {},
   "source": [
    "## PyTorch中的广播\n",
    "试试torch的广播功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba8738-ed68-429d-acc5-d90cbf491fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "t2=torch.sqrt(t1)\n",
    "t1/((t2+0.1)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76b2a7-2003-495d-a72f-46182c4ce1c7",
   "metadata": {},
   "source": [
    "## element-wise运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce160c3b-e90e-46af-a52c-012ef44c6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta=torch.ones(5)\n",
    "tb=torch.zeros(5)\n",
    "ta-tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5750178-331b-4b3e-9f08-219ea48846c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([2]).repeat(1,5)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b38e9-7140-4a64-b91a-aa1fa58fcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z/ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2bbd03-773e-48d1-b3c8-a8a37908f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "td=ta/z\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb95aa-c8e1-41d3-9f1a-f66c97f39455",
   "metadata": {},
   "outputs": [],
   "source": [
    "te=td**2\n",
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b92a3-4507-4ee6-93a5-cfd5b3a5b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = torch.arange(1., 5.)\n",
    "a = torch.arange(1., 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142dbcc4-70af-4779-bfb2-0d67a16fd34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7cf68f-132f-4971-9044-23f62a6517fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cb4c6-15e0-40e3-97c6-3048fce9e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.pow(a, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc16916-249f-4711-b1fc-f1e464641078",
   "metadata": {},
   "source": [
    "看看二维的情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbf0ab-6478-4806-a4c7-59574f6345c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "t2=t1.repeat(1,4).view(-1, 3)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78185f0-cbd6-497f-891e-98852b0ad641",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.FloatTensor([[7,8,9],[10,11,12]])\n",
    "t4=t3.repeat(1,4).view(-1, 3)\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4c8eb-45ac-4eb6-bde1-bbc2aa225370",
   "metadata": {},
   "outputs": [],
   "source": [
    "SST = (t4 - t2) ** 2\n",
    "SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f35290-df7d-4a27-8a65-6dd6f360bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SST=torch.sum(SST,dim=0)\n",
    "SST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce451123-dbac-45da-aa64-09eb2a891cae",
   "metadata": {},
   "source": [
    "## 比较大小\n",
    "两个张量，element-wise比较大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb62c1-972a-45af-a652-64477df67d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor((1, 2, -1))\n",
    "b = torch.tensor((3, 0, 4))\n",
    "torch.maximum(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ff4b1-3658-4f81-9cde-6128f8dc4399",
   "metadata": {},
   "source": [
    "如果张量大小不同，也会默认执行广播运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ae263-89c6-46d0-b9ef-3ff0b2ab4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor((1, 2, -1))\n",
    "b = torch.tensor([0])\n",
    "torch.maximum(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6c579-ee56-4158-ab6b-c670d07cac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "处理NaN值\n",
    "有时候会有一nan值需要处理。在torch中检测是否有nan值可以使用：x != x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b43905-2fa5-44d3-92cc-1ea78661f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nan==np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb028b8b-d36f-46b0-b8ca-e6786e0d6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.FloatTensor([[7,np.nan,9],[10,11,12]])\n",
    "t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cea91-c92f-4ed5-b4ea-5e959b572a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "如果是直接判断一个多维张量是否有nan值，可以使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c06f72-bf49-41d3-8485-9c2f18422182",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask= t5==t5\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8542a91-9691-4036-80c8-470e1021018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(mask[mask == True]) > 0:\n",
    "    print(\"please check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe226b8d-0444-458a-89b9-cc73f4a1b86e",
   "metadata": {},
   "source": [
    "please check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b7534-a534-4a3c-95e5-a820a8c33022",
   "metadata": {},
   "outputs": [],
   "source": [
    "t6=t5[mask]\n",
    "t6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d781e8-06a8-4c86-9b41-e347db407ab6",
   "metadata": {},
   "source": [
    "为了让一般的数值计算能够成为梯度可追踪的计算，我们有时候需要将常见的一些计算用tensor重写，下面是NSE的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f8275-d87c-4a80-82be-19d7ef62a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nse_2d(t,p):\n",
    "    seq_length = t.shape[0]\n",
    "    Ngage = t.shape[1]\n",
    "    tmean = torch.mean(t, dim=0)\n",
    "    tmeans = tmean.repeat(seq_length, 1)\n",
    "    SST = torch.sum((t - tmeans) ** 2, dim=0)\n",
    "    SSRes = torch.sum((t - p) ** 2, dim=0)\n",
    "    # Same as Fredrick 2019\n",
    "    # temp = SSRes / ((torch.sqrt(SST) + 0.1) ** 2)\n",
    "    # original NSE\n",
    "    temp = SSRes / SST\n",
    "    loss = torch.sum(temp) / Ngage\n",
    "    return loss\n",
    "\n",
    "t1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "t2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "print(nse_2d(t1,t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48756ca5-7628-4f7f-9600-abb599b2e65f",
   "metadata": {},
   "source": [
    "tensor(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27048faa-8aff-4b67-a973-a0a0c9f7d50f",
   "metadata": {},
   "source": [
    "# 对Tensor的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77515ad9-2c89-4d90-a1b8-96e1d95ac1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593757fe-8ea4-44e0-8e2a-68a43111b855",
   "metadata": {},
   "source": [
    "## 复制操作\n",
    "类似numpy的repeat和tile，torch中可以使用repeat："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f26349-966a-4875-8d62-828418e96619",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "z.repeat(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103170c-ea55-4231-87cc-19cc47023695",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.repeat(1,4).view(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac116d-866c-4fcd-a5bb-834351221b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.repeat(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62507b9-19a8-4c49-97d8-a61fd2f50fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f15355-3f28-412c-afdb-fa763bcc3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41190b4f-1267-47c7-8f5e-b7ac5d723ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[-1,:,:].repeat(3,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e58a183-e418-4f78-baaf-b874f82b4f8c",
   "metadata": {},
   "source": [
    "## 与numpy之间的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3e8ad-e13d-487d-b8b4-76f9e0496a0b",
   "metadata": {},
   "source": [
    "tensor 转换为numpy："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53f379-5f17-455b-990e-8d1066bfc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821a951-4d4b-4f84-86f1-3c179c76db1a",
   "metadata": {},
   "source": [
    "tensor([1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc99f9-5ab8-4dff-bea3-9552ac9d382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2934e2-77e0-4e3d-b2b5-97f009176114",
   "metadata": {},
   "source": [
    "[1. 1. 1. 1. 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2bafc-0b32-4e8b-ba09-67d882cc0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)    # see how the numpy array changed in value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e51cb3-14f2-40d3-b68b-604d6c2dc787",
   "metadata": {},
   "source": [
    "tensor([2., 2., 2., 2., 2.])\n",
    "[2. 2. 2. 2. 2.]\n",
    "注意tensor变化时，array也会跟着变。反过来也一样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f9b88-2fef-4188-b251-8ca3606297c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)  # see how changing the np array changed the torch Tensor automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03a791-8cf8-430d-81d1-76410fe5e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "[2. 2. 2. 2. 2.]\n",
    "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c829a-6eba-4d1b-a9f0-26b90d6d9233",
   "metadata": {},
   "source": [
    "## 维度变换\n",
    "再看看维度变换，三维变二维："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd5f18-7945-480d-b606-0bd93461d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t1 = torch.FloatTensor([[[7,8,9],[10,11,12]],[[7,8,9],[10,11,12]]])\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d31b2-176d-43c8-a35a-bdaa67fddb09",
   "metadata": {},
   "source": [
    "        [[ 7.,  8.,  9.],\n",
    "         [10., 11., 12.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad805999-bea5-499e-b552-0fef4efa0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=t1.view(-1, 3)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58966d-3443-4df6-bc08-9b61c3e464a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3=t1.reshape(-1, 3)\n",
    "t3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edabfb-b5bc-4007-b021-8f63c8f09f9c",
   "metadata": {},
   "source": [
    "reshape 和 view 的区别这里简单补充下，参考了：Pytorch-reshape与view的区别。Pytorch中reshape()与view()都可以改变Tensor的shape但是有略微的区别.\n",
    "\n",
    "- view()只可以由torch.Tensor.view()来调用，view():\n",
    "> 不改变Tensor数据，改变Tensor的size(即shape)\n",
    "> 对于一个将要被view的Tensor，新的size必须与原来的size与stride兼容,即新的维度必须是以下两种情况:\n",
    ">- 是原有维度的一个子空间\n",
    ">- 只跨越原有满足邻接条件，stride[i]=stride[i+1]×size[i+1]的原有维度d,d+1,…,d+k\\\n",
    "> 否则，在view之前必须调用contiguous()方法，对于该方法的讨论，见StackOverflow\n",
    "- reshape()可以由torch.reshape(),也可由torch.Tensor.reshape()调用。reshape():\n",
    ">同样也是返回与input数据量相同，但形状不同的tensor\n",
    ">若满足view的条件，则不会copy，若不满足，则会copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef16c4-84df-41bc-a2bb-41029d588863",
   "metadata": {},
   "source": [
    "## 张量转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb33f06-1c32-43b7-be0e-c814c7961249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ca8c6-6fbe-40e4-a724-a2bca74550cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.t(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tutorial)",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
